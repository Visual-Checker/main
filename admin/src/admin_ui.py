"""
ê´€ë¦¬ì UI - ì¶œê²°ê´€ë¦¬ ì‹œìŠ¤í…œ
ì‚¬ì§„, ëª©ì†Œë¦¬, ì œìŠ¤ì²˜ ë“±ë¡ ê¸°ëŠ¥
"""

import sys
import cv2
import os
import pickle
import numpy as np
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QLabel, QPushButton,
    QVBoxLayout, QHBoxLayout, QLineEdit, QMessageBox, QInputDialog, QFileDialog
)
from PyQt5.QtCore import Qt, QTimer, pyqtSignal
from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QColor

# ìŒì„± ì¸ì‹ ì„œë¹„ìŠ¤ import
from lib.voice_service import VoiceService

# ì œìŠ¤ì²˜ ì¸ì‹ ì„œë¹„ìŠ¤ import
from lib.gesture_service import GestureService

# MediaPipe import
MEDIAPIPE_AVAILABLE = False
USE_TASK_API = False
try:
    import mediapipe as mp
    try:
        from mediapipe.tasks import python
        from mediapipe.tasks.python import vision
        from mediapipe import Image as MPImage
        MEDIAPIPE_AVAILABLE = True
        USE_TASK_API = True
        print("âœ“ MediaPipe Task API ì‚¬ìš© ê°€ëŠ¥")
    except:
        USE_TASK_API = False
        MEDIAPIPE_AVAILABLE = False
        print("â„¹ï¸  MediaPipe Task APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenCVë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
except ImportError:
    print("âš ï¸  MediaPipeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# UI ì„¤ì • ì„í¬íŠ¸
from lib.ui_config_lib import *


class AdminUI(QMainWindow):
    """ê´€ë¦¬ì ëª¨ë“œ ë©”ì¸ ìœˆë„ìš°"""
    
    def __init__(self):
        super().__init__()
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.camera = None
        self.current_frame = None
        self.captured_frame = None
        self.current_name = ""
        
        # ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™”
        self.face_detector = None
        
        # ìŒì„± ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.voice_service = VoiceService()
        
        # ì œìŠ¤ì²˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        self.gesture_service = GestureService()
        
        if MEDIAPIPE_AVAILABLE and USE_TASK_API:
            try:
                base_options_face = python.BaseOptions(model_asset_path='models/blaze_face_short_range.tflite')
                face_options = vision.FaceDetectorOptions(base_options=base_options_face)
                self.face_detector = vision.FaceDetector.create_from_options(face_options)
                print("âœ“ MediaPipe ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸  MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("â„¹ï¸  ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: models/blaze_face_short_range.tflite")
        
        # ì–¼êµ´ ë°ì´í„° ë¡œë“œ
        self.known_face_features = []
        self.known_face_names = []
        self.load_face_data()
        
        # UI ì´ˆê¸°í™”
        self.init_ui()
        
        # ì¹´ë©”ë¼ ì‹œì‘
        self.start_camera()
        
    def init_ui(self):
        """UI ì´ˆê¸°í™”"""
        # ìœˆë„ìš° ì„¤ì •
        self.setWindowTitle(WINDOW_TITLE)
        self.setGeometry(100, 100, WINDOW_WIDTH, WINDOW_HEIGHT)
        self.setStyleSheet(f"background-color: {BG_COLOR};")
        
        # ì¤‘ì•™ ìœ„ì ¯
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ (ìˆ˜í‰)
        main_layout = QHBoxLayout(central_widget)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        # ì¢Œì¸¡ ì‚¬ì´ë“œë°” ìƒì„±
        sidebar = self.create_sidebar()
        main_layout.addWidget(sidebar)
        
        # ì¤‘ì•™ + ìš°ì¸¡ ì˜ì—­
        center_right_layout = QVBoxLayout()
        center_right_layout.setContentsMargins(20, 20, 20, 20)
        
        # ì¤‘ì•™(ì¹´ë©”ë¼) + ìš°ì¸¡(ë²„íŠ¼) ì˜ì—­
        cam_control_layout = QHBoxLayout()
        
        # ì¹´ë©”ë¼ ì˜ì—­
        self.camera_label = self.create_camera_view()
        cam_control_layout.addWidget(self.camera_label)
        
        # ìš°ì¸¡ ì»¨íŠ¸ë¡¤ ì˜ì—­
        right_panel = self.create_right_panel()
        cam_control_layout.addWidget(right_panel)
        
        center_right_layout.addLayout(cam_control_layout)
        
        # í•˜ë‹¨ ìƒíƒœë°”
        status_bar = self.create_status_bar()
        center_right_layout.addWidget(status_bar)
        
        main_layout.addLayout(center_right_layout)
        
    def create_sidebar(self):
        """ì¢Œì¸¡ ì‚¬ì´ë“œë°” ìƒì„±"""
        sidebar = QWidget()
        sidebar.setFixedWidth(SIDEBAR_WIDTH)
        sidebar.setStyleSheet(f"background-color: {SIDEBAR_COLOR};")
        
        layout = QVBoxLayout(sidebar)
        layout.setContentsMargins(SIDEBAR_PADDING, SIDEBAR_PADDING, SIDEBAR_PADDING, SIDEBAR_PADDING)
        layout.setSpacing(0)
        
        # ê´€ë¦¬ì ëª¨ë“œ ë¼ë²¨
        admin_label = QLabel("ğŸ” ê´€ë¦¬ì ëª¨ë“œ")
        admin_label.setFixedHeight(ADMIN_LABEL_HEIGHT)
        admin_label.setAlignment(Qt.AlignCenter)
        admin_label.setStyleSheet(f"""
            color: {TEXT_COLOR};
            font-size: {ADMIN_LABEL_FONT_SIZE}px;
            font-weight: {ADMIN_LABEL_FONT_WEIGHT};
            background-color: {ACCENT_COLOR};
            border-radius: 5px;
            padding: 10px;
        """)
        layout.addWidget(admin_label)
        
        layout.addSpacing(LEFT_BUTTON_START_Y - ADMIN_LABEL_HEIGHT - SIDEBAR_PADDING)
        
        # ì¢Œì¸¡ ë²„íŠ¼ë“¤ ìƒì„±
        self.left_buttons = {}
        for btn_config in LEFT_BUTTONS:
            btn = QPushButton(btn_config["text"])
            btn.setFixedSize(LEFT_BUTTON_WIDTH, LEFT_BUTTON_HEIGHT)
            btn.setStyleSheet(self.get_button_style())
            btn.setCursor(Qt.PointingHandCursor)
            
            # ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            btn_name = btn_config["name"]
            btn.clicked.connect(lambda checked, name=btn_name: self.on_left_button_click(name))
            
            self.left_buttons[btn_name] = btn
            layout.addWidget(btn)
            layout.addSpacing(LEFT_BUTTON_SPACING)
        
        layout.addStretch()
        
        return sidebar
    
    def create_camera_view(self):
        """ì¹´ë©”ë¼ ë·° ìƒì„±"""
        camera_label = QLabel()
        camera_label.setFixedSize(CAM_WIDTH, CAM_HEIGHT)
        camera_label.setAlignment(Qt.AlignCenter)
        camera_label.setStyleSheet(f"""
            background-color: {CAM_BG_COLOR};
            border: 2px solid {BUTTON_COLOR};
            border-radius: 5px;
        """)
        camera_label.setText("ğŸ“¹ ì¹´ë©”ë¼ ë¡œë”© ì¤‘...")
        camera_label.setFont(QFont("Arial", 14))
        camera_label.setStyleSheet(camera_label.styleSheet() + f"color: {TEXT_COLOR};")
        
        return camera_label
    
    def create_right_panel(self):
        """ìš°ì¸¡ ì»¨íŠ¸ë¡¤ íŒ¨ë„ ìƒì„±"""
        panel = QWidget()
        panel.setFixedWidth(RIGHT_BUTTON_WIDTH + 20)
        
        layout = QVBoxLayout(panel)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(RIGHT_BUTTON_SPACING)
        
        # ìš°ì¸¡ ë²„íŠ¼ë“¤ ìƒì„±
        self.right_buttons = {}
        for btn_config in RIGHT_BUTTONS:
            btn = QPushButton(btn_config["text"])
            btn.setFixedSize(RIGHT_BUTTON_WIDTH, RIGHT_BUTTON_HEIGHT)
            btn.setStyleSheet(self.get_button_style(font_size=RIGHT_BUTTON_FONT_SIZE))
            btn.setCursor(Qt.PointingHandCursor)
            
            # ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            btn_name = btn_config["name"]
            btn.clicked.connect(lambda checked, name=btn_name: self.on_right_button_click(name))
            
            self.right_buttons[btn_name] = btn
            layout.addWidget(btn)
        
        # ì´ë¦„ ì…ë ¥ í•„ë“œ
        layout.addSpacing(30)
        
        name_label = QLabel("ì´ë¦„:")
        name_label.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 11px;")
        layout.addWidget(name_label)
        
        self.name_input = QLineEdit()
        self.name_input.setFixedSize(INPUT_FIELD_WIDTH, INPUT_FIELD_HEIGHT)
        self.name_input.setPlaceholderText("ì´ë¦„ ì…ë ¥")
        self.name_input.setStyleSheet(self.get_input_style())
        layout.addWidget(self.name_input)
        
        layout.addStretch()
        
        return panel
    
    def create_status_bar(self):
        """í•˜ë‹¨ ìƒíƒœë°” ìƒì„±"""
        status_bar = QLabel("âœ… ì¤€ë¹„ ì™„ë£Œ")
        status_bar.setFixedHeight(STATUS_BAR_HEIGHT)
        status_bar.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)
        status_bar.setStyleSheet(f"""
            background-color: {STATUS_BAR_BG_COLOR};
            color: {TEXT_COLOR};
            font-size: {STATUS_FONT_SIZE}px;
            padding-left: 15px;
            border-radius: 5px;
        """)
        self.status_bar = status_bar
        return status_bar
    
    def load_face_data(self):
        """ì €ì¥ëœ ì–¼êµ´ ë°ì´í„° ë¡œë“œ"""
        face_data_file = "../data/face_data.pkl"
        
        if os.path.exists(face_data_file):
            try:
                with open(face_data_file, 'rb') as f:
                    data = pickle.load(f)
                    self.known_face_features = data.get('features', [])
                    self.known_face_names = data.get('names', [])
                print(f"âœ“ {len(self.known_face_names)}ëª…ì˜ ì–¼êµ´ ë°ì´í„° ë¡œë“œë¨")
            except Exception as e:
                print(f"âš ï¸  ì–¼êµ´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("â„¹ï¸  ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def save_face_data(self):
        """ì–¼êµ´ ë°ì´í„° ì €ì¥"""
        face_data_file = "../data/face_data.pkl"
        os.makedirs(os.path.dirname(face_data_file), exist_ok=True)
        
        data = {
            'features': self.known_face_features,
            'names': self.known_face_names
        }
        
        try:
            with open(face_data_file, 'wb') as f:
                pickle.dump(data, f)
            print(f"âœ“ ì–¼êµ´ ë°ì´í„° ì €ì¥ë¨: {len(self.known_face_names)}ëª…")
        except Exception as e:
            print(f"âš ï¸  ì–¼êµ´ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def extract_face_features(self, detection, image_width, image_height):
        """ì–¼êµ´ ê°ì§€ ê²°ê³¼ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ"""
        bbox = detection.bounding_box
        features = [
            bbox.origin_x / image_width,
            bbox.origin_y / image_height,
            bbox.width / image_width,
            bbox.height / image_height
        ]
        return np.array(features)
    
    def get_button_style(self, font_size=LEFT_BUTTON_FONT_SIZE):
        """ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë°˜í™˜"""
        return f"""
            QPushButton {{
                background-color: {BUTTON_COLOR};
                color: {TEXT_COLOR};
                border: none;
                border-radius: 5px;
                font-size: {font_size}px;
                font-weight: bold;
                padding: 5px;
            }}
            QPushButton:hover {{
                background-color: {BUTTON_HOVER_COLOR};
            }}
            QPushButton:pressed {{
                background-color: #1F618D;
            }}
        """
    
    def get_input_style(self):
        """ì…ë ¥ í•„ë“œ ìŠ¤íƒ€ì¼ ë°˜í™˜"""
        return f"""
            QLineEdit {{
                background-color: {CAM_BG_COLOR};
                color: {TEXT_COLOR};
                border: 2px solid {BUTTON_COLOR};
                border-radius: 5px;
                padding: 5px;
                font-size: 11px;
            }}
            QLineEdit:focus {{
                border: 2px solid {BUTTON_HOVER_COLOR};
            }}
        """
    
    def start_camera(self):
        """ì¹´ë©”ë¼ ì‹œì‘"""
        self.camera = cv2.VideoCapture(CAMERA_INDEX)
        
        if not self.camera.isOpened():
            self.update_status("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", error=True)
            return
        
        # ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
        
        # íƒ€ì´ë¨¸ë¡œ í”„ë ˆì„ ì—…ë°ì´íŠ¸
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(int(1000 / CAMERA_FPS))
        
        self.update_status("ğŸ“¹ ì¹´ë©”ë¼ í™œì„±í™”ë¨")
    
    def update_frame(self):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
        ret, frame = self.camera.read()
        
        if ret:
            self.current_frame = frame
            display_frame = frame.copy()
            
            # ì–¼êµ´ ê°ì§€ ì˜¤ë²„ë ˆì´
            if self.face_detector:
                rgb_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
                mp_image = MPImage(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
                detection_result = self.face_detector.detect(mp_image)
                
                if detection_result.detections:
                    for detection in detection_result.detections:
                        bbox = detection.bounding_box
                        x_min = int(bbox.origin_x)
                        y_min = int(bbox.origin_y)
                        x_max = int(bbox.origin_x + bbox.width)
                        y_max = int(bbox.origin_y + bbox.height)
                        
                        cv2.rectangle(display_frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)
                        
                        for keypoint in detection.keypoints:
                            h, w, _ = display_frame.shape
                            kp_x = int(keypoint.x * w)
                            kp_y = int(keypoint.y * h)
                            cv2.circle(display_frame, (kp_x, kp_y), 3, (0, 255, 255), -1)
                    
                    cv2.putText(display_frame, "Face Detected", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                else:
                    cv2.putText(display_frame, "No Face Detected", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            else:
                # OpenCV Haar Cascade fallback
                gray = cv2.cvtColor(display_frame, cv2.COLOR_BGR2GRAY)
                face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                faces = face_cascade.detectMultiScale(gray, 1.1, 4)
                
                for (x, y, w, h) in faces:
                    cv2.rectangle(display_frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                
                if len(faces) > 0:
                    cv2.putText(display_frame, "Face Detected (OpenCV)", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                else:
                    cv2.putText(display_frame, "No Face Detected", (10, 30), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)
            
            # BGRì„ RGBë¡œ ë³€í™˜
            rgb_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            
            # QImageë¡œ ë³€í™˜
            h, w, ch = rgb_frame.shape
            bytes_per_line = ch * w
            qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            
            # QLabelì— í‘œì‹œ
            pixmap = QPixmap.fromImage(qt_image)
            scaled_pixmap = pixmap.scaled(CAM_WIDTH, CAM_HEIGHT, Qt.KeepAspectRatio)
            self.camera_label.setPixmap(scaled_pixmap)
    
    def on_left_button_click(self, button_name):
        """ì¢Œì¸¡ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸"""
        if button_name == "photo_register":
            self.update_status("ğŸ“· ì‚¬ì§„ ë“±ë¡ ëª¨ë“œ")
            QMessageBox.information(self, "ì‚¬ì§„ ë“±ë¡", "ì‚¬ì§„ ë“±ë¡ ê¸°ëŠ¥ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤.")
        elif button_name == "voice_register":
            # ìŒì„± ë“±ë¡/ì¸ì‹ ì˜µì…˜ ì„ íƒ
            options = ["ìŒì„± ë“±ë¡", "ìŒì„± ì¸ì‹"]
            choice, ok = QInputDialog.getItem(
                self,
                "ìŒì„± ëª¨ë“œ ì„ íƒ",
                "ìˆ˜í–‰í•  ì‘ì—…ì„ ì„ íƒí•˜ì„¸ìš”:",
                options,
                0,
                False
            )
            
            if ok:
                if choice == "ìŒì„± ë“±ë¡":
                    self.voice_register_mode()
                elif choice == "ìŒì„± ì¸ì‹":
                    self.voice_recognize_mode()
        elif button_name == "gesture_register":
            self.gesture_register_mode()
    
    def on_right_button_click(self, button_name):
        """ìš°ì¸¡ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸"""
        if button_name == "capture":
            self.capture_photo()
        elif button_name == "save":
            self.save_photo()
        elif button_name == "input_info":
            self.input_user_info()
    
    def capture_photo(self):
        """ì‚¬ì§„ ì°ê¸°"""
        if self.current_frame is not None:
            self.captured_frame = self.current_frame.copy()
            self.update_status("ğŸ“¸ ì‚¬ì§„ì´ ìº¡ì²˜ë˜ì—ˆìŠµë‹ˆë‹¤")
            QMessageBox.information(self, "ìº¡ì²˜ ì™„ë£Œ", "ì‚¬ì§„ì´ ìº¡ì²˜ë˜ì—ˆìŠµë‹ˆë‹¤.\n'ì‚¬ì§„ ì €ì¥' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì €ì¥í•˜ì„¸ìš”.")
        else:
            self.update_status("âŒ ì¹´ë©”ë¼ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤", error=True)
    
    def save_photo(self):
        """ì‚¬ì§„ ì €ì¥"""
        if self.captured_frame is None:
            self.update_status("âŒ ì €ì¥í•  ì‚¬ì§„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ì‚¬ì§„ì„ ì°ì–´ì£¼ì„¸ìš”.", error=True)
            QMessageBox.warning(self, "ì €ì¥ ì‹¤íŒ¨", "ë¨¼ì € 'ì‚¬ì§„ì°ê¸°' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‚¬ì§„ì„ ì°ì–´ì£¼ì„¸ìš”.")
            return
        
        name = self.name_input.text().strip()
        
        if not name:
            self.update_status("âŒ ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”", error=True)
            QMessageBox.warning(self, "ì…ë ¥ í•„ìš”", "ì´ë¦„ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ì–¼êµ´ ê°ì§€ ë° íŠ¹ì§• ì¶”ì¶œ
        if MEDIAPIPE_AVAILABLE and self.face_detector:
            rgb_frame = cv2.cvtColor(self.captured_frame, cv2.COLOR_BGR2RGB)
            mp_image = MPImage(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
            detection_result = self.face_detector.detect(mp_image)
            
            if not detection_result.detections:
                reply = QMessageBox.question(
                    self, 
                    "ì–¼êµ´ ê°ì§€ ì•ˆë¨", 
                    "ì‚¬ì§„ì—ì„œ ì–¼êµ´ì„ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\nê·¸ë˜ë„ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
                    QMessageBox.Yes | QMessageBox.No
                )
                if reply == QMessageBox.No:
                    return
            elif len(detection_result.detections) > 1:
                QMessageBox.warning(
                    self, 
                    "ì—¬ëŸ¬ ì–¼êµ´ ê°ì§€", 
                    f"{len(detection_result.detections)}ê°œì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.\ní•œ ëª…ë§Œ ì´¬ì˜í•´ì£¼ì„¸ìš”."
                )
                return
            
            # ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
            if detection_result.detections and len(detection_result.detections) == 1:
                h, w, _ = self.captured_frame.shape
                face_features = self.extract_face_features(detection_result.detections[0], w, h)
                
                # ê¸°ì¡´ ë°ì´í„°ì— ì¶”ê°€
                self.known_face_features.append(face_features)
                self.known_face_names.append(name)
                
                # íŒŒì¼ë¡œ ì €ì¥
                self.save_face_data()
                
                self.update_status(f"âœ“ ì–¼êµ´ ë°ì´í„° ì €ì¥ë¨: {name}")
                face_registered = "O"
            else:
                face_registered = "X"
        else:
            face_registered = "X"
        
        # íŒŒì¼ëª… ìƒì„±
        import datetime
        
        save_dir = "../data/photos"
        os.makedirs(save_dir, exist_ok=True)
        
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{save_dir}/{name}_{timestamp}.jpg"
        
        # ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(filename, self.captured_frame)
        
        
        self.update_status(f"ğŸ’¾ ì €ì¥ ì™„ë£Œ: {filename}")
        QMessageBox.information(self, "ì €ì¥ ì™„ë£Œ", f"ì‚¬ì§„ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n\níŒŒì¼: {filename}\nì–¼êµ´ ë“±ë¡: {face_registered}")
        
        # ì…ë ¥ í•„ë“œ ì´ˆê¸°í™”
        self.name_input.clear()
        self.captured_frame = None
    
    def input_user_info(self):
        """ì‚¬ìš©ì ì •ë³´ ì…ë ¥ ë‹¤ì´ì–¼ë¡œê·¸"""
        name, ok = QInputDialog.getText(self, "ì´ë¦„ ì…ë ¥", "ì´ë¦„:")
        if ok and name:
            self.name_input.setText(name)
            self.update_status(f"âœï¸ ì…ë ¥ ì™„ë£Œ: {name}")
    
    def update_status(self, message, error=False):
        """ìƒíƒœë°” ì—…ë°ì´íŠ¸"""
        if error:
            self.status_bar.setStyleSheet(
                self.status_bar.styleSheet().replace(STATUS_BAR_BG_COLOR, ACCENT_COLOR)
            )
        else:
            self.status_bar.setStyleSheet(
                self.status_bar.styleSheet().replace(ACCENT_COLOR, STATUS_BAR_BG_COLOR)
            )
        self.status_bar.setText(message)
    
    def voice_register_mode(self):
        """ìŒì„± ë“±ë¡ ëª¨ë“œ (ìŒì„± ë…¹ìŒ)"""
        # ì‚¬ìš©ì ì´ë¦„ ì…ë ¥
        name, ok = QInputDialog.getText(
            self,
            "ì‚¬ìš©ì ì´ë¦„ ì…ë ¥",
            "ë“±ë¡í•  ì‚¬ìš©ìì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:"
        )
        
        if not ok or not name.strip():
            self.update_status("âŒ ì‚¬ìš©ì ì´ë¦„ ì…ë ¥ ì·¨ì†Œë¨")
            return
        
        name = name.strip()
        
        # ë…¹ìŒ ì‹œê°„ ì…ë ¥ (ê¸°ë³¸ê°’: 3ì´ˆ)
        duration, ok = QInputDialog.getInt(
            self,
            "ë…¹ìŒ ì‹œê°„ ì„¤ì •",
            "ë…¹ìŒ ì‹œê°„(ì´ˆ)ì„ ì…ë ¥í•˜ì„¸ìš”:",
            3,
            1,
            10
        )
        
        if not ok:
            self.update_status("âŒ ë…¹ìŒ ì‹œê°„ ì„¤ì • ì·¨ì†Œë¨")
            return
        
        # ë…¹ìŒ í™•ì¸
        confirm = QMessageBox.question(
            self,
            "ë…¹ìŒ ì‹œì‘",
            f"{name}ì˜ ìŒì„±ì„ {duration}ì´ˆê°„ ë…¹ìŒí•©ë‹ˆë‹¤.\në§ˆì´í¬ë¥¼ ì¤€ë¹„í•˜ì„¸ìš”.\nê³„ì†í• ê¹Œìš”?"
        )
        
        if confirm != QMessageBox.Yes:
            self.update_status("âŒ ìŒì„± ë…¹ìŒ ì·¨ì†Œë¨")
            return
        
        # ìŒì„± ë…¹ìŒ
        self.update_status(f"ğŸ¤ ìŒì„± ë…¹ìŒ ì¤‘... ({duration}ì´ˆ)")
        
        try:
            import sounddevice as sd
            import soundfile as sf
            import numpy as np
            
            # ì˜¤ë””ì˜¤ ì¥ì¹˜ í™•ì¸
            try:
                devices = sd.query_devices()
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ì˜¤ë””ì˜¤ ì¥ì¹˜:")
                print(devices)
                
                # ì…ë ¥ ì¥ì¹˜ ì°¾ê¸°
                input_devices = []
                for i, device in enumerate(devices):
                    if device['max_input_channels'] > 0:
                        input_devices.append((i, device['name']))
                
                if not input_devices:
                    raise Exception("ë§ˆì´í¬ ì…ë ¥ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                print(f"ë°œê²¬ëœ ì…ë ¥ ì¥ì¹˜: {len(input_devices)}ê°œ")
                for idx, name in input_devices:
                    print(f"  [{idx}] {name}")
                
                # ì²« ë²ˆì§¸ ì…ë ¥ ì¥ì¹˜ë¥¼ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
                device_id = input_devices[0][0]
                device_name = input_devices[0][1]
                print(f"ì‚¬ìš©í•  ì¥ì¹˜: [{device_id}] {device_name}")
                
            except Exception as device_error:
                self.update_status(f"âŒ ì˜¤ë””ì˜¤ ì¥ì¹˜ í™•ì¸ ì‹¤íŒ¨: {str(device_error)}")
                QMessageBox.warning(
                    self,
                    "ì˜¤ë””ì˜¤ ì¥ì¹˜ ì˜¤ë¥˜",
                    f"ì˜¤ë””ì˜¤ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në§ˆì´í¬ê°€ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\n\nì—ëŸ¬: {str(device_error)}"
                )
                return
            
            # ì„ì‹œ ìŒì„± íŒŒì¼ ì €ì¥
            temp_audio_file = "./tmp_voice_recording.wav"
            sample_rate = 16000
            
            # ë…¹ìŒ
            print(f"ğŸ¤ ë…¹ìŒ ì‹œì‘... ({duration}ì´ˆ)")
            QMessageBox.information(
                self,
                "ë…¹ìŒ ì‹œì‘",
                f"{duration}ì´ˆ í›„ ìë™ìœ¼ë¡œ ì¢…ë£Œë©ë‹ˆë‹¤.\nì§€ê¸ˆë¶€í„° ë§ì”€í•˜ì„¸ìš”!"
            )
            
            audio_data = sd.rec(
                int(duration * sample_rate), 
                samplerate=sample_rate, 
                channels=1, 
                dtype='float32',
                device=device_id  # ëª…ì‹œì ìœ¼ë¡œ ì¥ì¹˜ ì§€ì •
            )
            sd.wait()  # ë…¹ìŒ ì™„ë£Œ ëŒ€ê¸°
            
            # íŒŒì¼ë¡œ ì €ì¥
            sf.write(temp_audio_file, audio_data, sample_rate)
            print(f"âœ“ ë…¹ìŒ ì™„ë£Œ: {temp_audio_file}")
            
            # ìŒì„± ë°ì´í„° ë“±ë¡
            self.update_status(f"ğŸ¤ ìŒì„± ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({name})")
            
            success = self.voice_service.register_voice(temp_audio_file, name)
            
            if success:
                self.voice_service.save_voice_data()
                self.update_status(f"âœ… {name}ì˜ ìŒì„± ë°ì´í„° ë“±ë¡ ì™„ë£Œ")
                QMessageBox.information(
                    self,
                    "ë“±ë¡ ì™„ë£Œ",
                    f"{name}ì˜ ìŒì„± ë°ì´í„°ê°€ ì„±ê³µì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤."
                )
            else:
                self.update_status("âŒ ìŒì„± ë°ì´í„° ë“±ë¡ ì‹¤íŒ¨")
                QMessageBox.warning(
                    self,
                    "ë“±ë¡ ì‹¤íŒ¨",
                    "ìŒì„± ë°ì´í„° ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\në‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
                )
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            if os.path.exists(temp_audio_file):
                os.remove(temp_audio_file)
                
        except ImportError:
            self.update_status("âŒ ìŒì„± ë…¹ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ")
            QMessageBox.warning(
                self,
                "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜",
                "sounddevice ë° soundfileì´ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\nì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”."
            )
        except Exception as e:
            self.update_status(f"âŒ ìŒì„± ë…¹ìŒ ì˜¤ë¥˜: {str(e)}")
            QMessageBox.warning(
                self,
                "ë…¹ìŒ ì˜¤ë¥˜",
                f"ìŒì„± ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:\n{str(e)}"
            )
    
    def gesture_register_mode(self):
        """ì œìŠ¤ì²˜ ë“±ë¡ ëª¨ë“œ"""
        self.update_status("ğŸ‘‹ ì œìŠ¤ì²˜ ë“±ë¡ ëª¨ë“œ í™œì„±í™”")
        
        # ì œìŠ¤ì²˜ íƒ€ì… ì„ íƒ
        gesture_types = ["OK", "Pointing_Up", "Thumbs_Down", "Thumbs_Up", "Victory", "Open_Palm", "Closed_Fist"]
        
        gesture_dialog = QInputDialog()
        gesture_type, ok = gesture_dialog.getItem(
            self,
            "ì œìŠ¤ì²˜ íƒ€ì… ì„ íƒ",
            "ë“±ë¡í•  ì œìŠ¤ì²˜ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            gesture_types,
            0,
            False
        )
        
        if not ok or not gesture_type:
            self.update_status("âŒ ì œìŠ¤ì²˜ íƒ€ì… ì„ íƒ ì·¨ì†Œë¨")
            return
        
        # ì‚¬ìš©ì ì´ë¦„ ì…ë ¥
        user_name, ok = QInputDialog.getText(
            self,
            "ì‚¬ìš©ì ì •ë³´ ì…ë ¥",
            "ë“±ë¡í•  ì‚¬ìš©ìì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:"
        )
        
        if not ok or not user_name.strip():
            self.update_status("âŒ ì‚¬ìš©ì ì´ë¦„ ì…ë ¥ ì·¨ì†Œë¨")
            return
        
        user_name = user_name.strip()
        
        # ì¹´ë©”ë¼ì—ì„œ ì œìŠ¤ì²˜ ìº¡ì²˜
        self.update_status(f"ğŸ‘‹ {gesture_type} ì œìŠ¤ì²˜ë¥¼ ë³´ì—¬ì£¼ì„¸ìš”... (ì¹´ë©”ë¼ í™•ì¸)")
        
        # 3ì´ˆ ë™ì•ˆ í”„ë ˆì„ ìº¡ì²˜
        capture_count = 0
        max_captures = 5  # 5ê°œ í”„ë ˆì„ ìº¡ì²˜
        success_count = 0
        
        for i in range(90):  # 3ì´ˆ (30fps * 3)
            ret, frame = self.camera.read()
            
            if ret:
                self.current_frame = frame
                
                # ë§¤ 18í”„ë ˆì„ë§ˆë‹¤ ìº¡ì²˜ ì‹œë„ (ëŒ€ëµ 0.6ì´ˆ ê°„ê²©)
                if i % 18 == 0 and capture_count < max_captures:
                    if self.gesture_service.register_gesture(frame, gesture_type, user_name):
                        success_count += 1
                    capture_count += 1
                
                # UI ì—…ë°ì´íŠ¸ (ë””ìŠ¤í”Œë ˆì´ë§Œ)
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                h, w, ch = rgb_frame.shape
                bytes_per_line = ch * w
                qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
                pixmap = QPixmap.fromImage(qt_image)
                scaled_pixmap = pixmap.scaled(CAM_WIDTH, CAM_HEIGHT, Qt.KeepAspectRatio)
                self.camera_label.setPixmap(scaled_pixmap)
                
                QApplication.processEvents()
        
        # ê²°ê³¼ ì²˜ë¦¬
        if success_count > 0:
            self.gesture_service.save_gesture_data()
            self.update_status(f"âœ… {user_name}ì˜ '{gesture_type}' ì œìŠ¤ì²˜ {success_count}ê°œ ë“±ë¡ ì™„ë£Œ")
            QMessageBox.information(
                self,
                "ë“±ë¡ ì™„ë£Œ",
                f"{user_name}ì˜ '{gesture_type}' ì œìŠ¤ì²˜ {success_count}ê°œê°€ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤."
            )
        else:
            self.update_status("âŒ ì œìŠ¤ì²˜ ë“±ë¡ ì‹¤íŒ¨ - ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”")
            QMessageBox.warning(
                self,
                "ë“±ë¡ ì‹¤íŒ¨",
                "ì œìŠ¤ì²˜ ë“±ë¡ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\nì œìŠ¤ì²˜ë¥¼ ëª…í™•í•˜ê²Œ ë³´ì—¬ì£¼ì„¸ìš”."
            )
    
    def voice_recognize_mode(self):
        """ìŒì„± ì¸ì‹ ëª¨ë“œ"""
        self.update_status("ğŸ¤ ìŒì„± íŒŒì¼ ì„ íƒ ëŒ€ê¸° ì¤‘...")
        
        # ìŒì„± íŒŒì¼ ì„ íƒ
        audio_file, _ = QFileDialog.getOpenFileName(
            self,
            "ìŒì„± íŒŒì¼ ì„ íƒ",
            "",
            "ìŒì„± íŒŒì¼ (*.wav *.mp3 *.flac);;ëª¨ë“  íŒŒì¼ (*)"
        )
        
        if not audio_file:
            self.update_status("âŒ ìŒì„± íŒŒì¼ ì„ íƒ ì·¨ì†Œë¨")
            return
        
        # ìŒì„± ì¸ì‹ ì‹¤í–‰
        self.update_status(f"ğŸ¤ ìŒì„± ì¸ì‹ ì¤‘... ({os.path.basename(audio_file)})")
        
        name, similarity = self.voice_service.recognize_voice(audio_file)
        
        if name != "Unknown" and similarity > self.voice_service.voice_similarity_threshold:
            self.update_status(f"âœ… {name} ì¸ì‹ë¨ (ìœ ì‚¬ë„: {similarity:.3f})")
            QMessageBox.information(
                self,
                "ì¸ì‹ ì„±ê³µ",
                f"ìŒì„± ì¸ì‹ ì™„ë£Œ:\nì´ë¦„: {name}\nìœ ì‚¬ë„: {similarity:.3f}"
            )
        else:
            self.update_status("âŒ ìŒì„± ì¸ì‹ ì‹¤íŒ¨ - ë“±ë¡ëœ ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            QMessageBox.warning(
                self,
                "ì¸ì‹ ì‹¤íŒ¨",
                "ë“±ë¡ëœ ì‚¬ìš©ìì˜ ìŒì„±ê³¼ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."
            )
    
    def closeEvent(self, event):
        """ìœˆë„ìš° ì¢…ë£Œ ì´ë²¤íŠ¸"""
        if self.camera is not None:
            self.camera.release()
        event.accept()


def main():
    app = QApplication(sys.argv)
    
    # ë‹¤í¬ í…Œë§ˆ ì ìš©
    app.setStyle('Fusion')
    palette = QPalette()
    palette.setColor(QPalette.Window, QColor(44, 62, 80))
    palette.setColor(QPalette.WindowText, Qt.white)
    app.setPalette(palette)
    
    window = AdminUI()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
