"""
í´ë¼ì´ì–¸íŠ¸ UI - ì¶œê²°ê´€ë¦¬ ì‹œìŠ¤í…œ
ì œìŠ¤ì²˜ ë° ì–¼êµ´ ì¸ì‹ ì¶œì„ ì²´í¬
"""

import sys
import cv2
import os
import pickle
import numpy as np
from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QWidget, QLabel, QPushButton,
    QVBoxLayout, QHBoxLayout, QMessageBox, QFrame
)
from PyQt5.QtCore import Qt, QTimer
from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QColor

# MediaPipe import
MEDIAPIPE_AVAILABLE = False
try:
    import mediapipe as mp
    # Task API import ì‹œë„
    try:
        from mediapipe.tasks import python
        from mediapipe.tasks.python import vision
        from mediapipe import Image as MPImage
        MEDIAPIPE_AVAILABLE = True
        USE_TASK_API = True
        print("âœ“ MediaPipe Task API ì‚¬ìš© ê°€ëŠ¥")
    except:
        # Task API ì—†ìœ¼ë©´ OpenCVë§Œ ì‚¬ìš©
        USE_TASK_API = False
        MEDIAPIPE_AVAILABLE = False
        print("â„¹ï¸  MediaPipe Task APIë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. OpenCVë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
except ImportError:
    print("âš ï¸  MediaPipeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# UI ì„¤ì • ì„í¬íŠ¸
from ui_config_lib import *


class ClientUI(QMainWindow):
    """í´ë¼ì´ì–¸íŠ¸ ì¶œì„ ì²´í¬ ìœˆë„ìš°"""
    
    def __init__(self):
        super().__init__()
        
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        self.camera = None
        self.current_frame = None
        self.current_mode = None  # 'gesture', 'face', None
        self.current_user = None
        
        # ì–¼êµ´ ê°ì§€ê¸° ì´ˆê¸°í™”
        self.face_detector = None
        self.gesture_recognizer = None
        
        if MEDIAPIPE_AVAILABLE and USE_TASK_API:
            try:
                # ì–¼êµ´ ê°ì§€ê¸°
                base_options_face = python.BaseOptions(model_asset_path='models/blaze_face_short_range.tflite')
                face_options = vision.FaceDetectorOptions(base_options=base_options_face)
                self.face_detector = vision.FaceDetector.create_from_options(face_options)
                
                # ì œìŠ¤ì²˜ ì¸ì‹ê¸°
                base_options_gesture = python.BaseOptions(model_asset_path='models/gesture_recognizer.task')
                gesture_options = vision.GestureRecognizerOptions(base_options=base_options_gesture)
                self.gesture_recognizer = vision.GestureRecognizer.create_from_options(gesture_options)
                
                print("âœ“ MediaPipe Task API ì´ˆê¸°í™” ì„±ê³µ")
            except Exception as e:
                print(f"âš ï¸  MediaPipe ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                print("â„¹ï¸  ëª¨ë¸ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”: models/blaze_face_short_range.tflite, models/gesture_recognizer.task")
        
        # ì–¼êµ´ì¸ì‹ ë°ì´í„° ë¡œë“œ
        self.known_face_features = []
        self.known_face_names = []
        self.load_face_data()
        
        # UI ì´ˆê¸°í™”
        self.init_ui()
        
        # ì¹´ë©”ë¼ ì‹œì‘
        self.start_camera()
        
    def init_ui(self):
        """UI ì´ˆê¸°í™”"""
        # ìœˆë„ìš° ì„¤ì •
        self.setWindowTitle(WINDOW_TITLE)
        self.setGeometry(100, 100, WINDOW_WIDTH, WINDOW_HEIGHT)
        self.setStyleSheet(f"background-color: {BG_COLOR};")
        
        # ì¤‘ì•™ ìœ„ì ¯
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        # ë©”ì¸ ë ˆì´ì•„ì›ƒ (ìˆ˜í‰)
        main_layout = QHBoxLayout(central_widget)
        main_layout.setContentsMargins(0, 0, 0, 0)
        main_layout.setSpacing(0)
        
        # ì¢Œì¸¡ ì‚¬ì´ë“œë°” ìƒì„±
        sidebar = self.create_sidebar()
        main_layout.addWidget(sidebar)
        
        # ì¤‘ì•™ + ìš°ì¸¡ ì˜ì—­
        center_right_layout = QVBoxLayout()
        center_right_layout.setContentsMargins(20, 20, 20, 20)
        
        # ì¤‘ì•™(ì¹´ë©”ë¼) + ìš°ì¸¡(ì •ë³´) ì˜ì—­
        cam_info_layout = QHBoxLayout()
        
        # ì¹´ë©”ë¼ ì˜ì—­
        self.camera_label = self.create_camera_view()
        cam_info_layout.addWidget(self.camera_label)
        
        # ìš°ì¸¡ ì •ë³´ íŒ¨ë„
        right_panel = self.create_right_panel()
        cam_info_layout.addWidget(right_panel)
        
        center_right_layout.addLayout(cam_info_layout)
        
        # í•˜ë‹¨ ì œìŠ¤ì²˜ ê°€ì´ë“œ
        gesture_guide = self.create_gesture_guide()
        center_right_layout.addWidget(gesture_guide)
        
        # í•˜ë‹¨ ìƒíƒœë°”
        status_bar = self.create_status_bar()
        center_right_layout.addWidget(status_bar)
        
        main_layout.addLayout(center_right_layout)
        
    def create_sidebar(self):
        """ì¢Œì¸¡ ì‚¬ì´ë“œë°” ìƒì„±"""
        sidebar = QWidget()
        sidebar.setFixedWidth(SIDEBAR_WIDTH)
        sidebar.setStyleSheet(f"background-color: {SIDEBAR_COLOR};")
        
        layout = QVBoxLayout(sidebar)
        layout.setContentsMargins(SIDEBAR_PADDING, SIDEBAR_PADDING, SIDEBAR_PADDING, SIDEBAR_PADDING)
        layout.setSpacing(0)
        
        # í´ë¼ì´ì–¸íŠ¸ ëª¨ë“œ ë¼ë²¨
        client_label = QLabel("ğŸ“± ì¶œì„ ì²´í¬")
        client_label.setFixedHeight(CLIENT_LABEL_HEIGHT)
        client_label.setAlignment(Qt.AlignCenter)
        client_label.setStyleSheet(f"""
            color: {TEXT_COLOR};
            font-size: {CLIENT_LABEL_FONT_SIZE}px;
            font-weight: {CLIENT_LABEL_FONT_WEIGHT};
            background-color: {ACCENT_COLOR};
            border-radius: 5px;
            padding: 10px;
        """)
        layout.addWidget(client_label)
        
        layout.addSpacing(LEFT_BUTTON_START_Y - CLIENT_LABEL_HEIGHT - SIDEBAR_PADDING)
        
        # ì¢Œì¸¡ ë²„íŠ¼ë“¤ ìƒì„±
        self.left_buttons = {}
        for btn_config in LEFT_BUTTONS:
            btn = QPushButton(btn_config["text"])
            btn.setFixedSize(LEFT_BUTTON_WIDTH, LEFT_BUTTON_HEIGHT)
            btn.setStyleSheet(self.get_button_style())
            btn.setCursor(Qt.PointingHandCursor)
            
            # ë²„íŠ¼ ì´ë²¤íŠ¸ ì—°ê²°
            btn_name = btn_config["name"]
            btn.clicked.connect(lambda checked, name=btn_name: self.on_mode_button_click(name))
            
            self.left_buttons[btn_name] = btn
            layout.addWidget(btn)
            layout.addSpacing(LEFT_BUTTON_SPACING)
        
        layout.addStretch()
        
        return sidebar
    
    def create_camera_view(self):
        """ì¹´ë©”ë¼ ë·° ìƒì„±"""
        camera_label = QLabel()
        camera_label.setFixedSize(CAM_WIDTH, CAM_HEIGHT)
        camera_label.setAlignment(Qt.AlignCenter)
        camera_label.setStyleSheet(f"""
            background-color: {CAM_BG_COLOR};
            border: 3px solid {ACCENT_COLOR};
            border-radius: 10px;
        """)
        camera_label.setText("ğŸ“¹ ì¹´ë©”ë¼ ë¡œë”© ì¤‘...")
        camera_label.setFont(QFont("Arial", 14))
        camera_label.setStyleSheet(camera_label.styleSheet() + f"color: {TEXT_COLOR};")
        
        return camera_label
    
    def create_right_panel(self):
        """ìš°ì¸¡ ì •ë³´ íŒ¨ë„ ìƒì„±"""
        panel = QWidget()
        panel.setFixedWidth(RIGHT_PANEL_WIDTH)
        
        layout = QVBoxLayout(panel)
        layout.setContentsMargins(0, 0, 0, 0)
        layout.setSpacing(15)
        
        # ì‚¬ìš©ì ì •ë³´ í”„ë ˆì„
        user_info_frame = QFrame()
        user_info_frame.setFixedHeight(USER_INFO_HEIGHT)
        user_info_frame.setStyleSheet(f"""
            background-color: {USER_INFO_BG_COLOR};
            border-radius: 8px;
            padding: 10px;
        """)
        
        user_info_layout = QVBoxLayout(user_info_frame)
        
        user_title = QLabel("ğŸ‘¤ ì‚¬ìš©ì ì •ë³´")
        user_title.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 14px; font-weight: bold;")
        user_info_layout.addWidget(user_title)
        
        self.user_name_label = QLabel("ì´ë¦„: -")
        self.user_name_label.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 12px;")
        user_info_layout.addWidget(self.user_name_label)
        
        self.user_id_label = QLabel("í•™ë²ˆ: -")
        self.user_id_label.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 12px;")
        user_info_layout.addWidget(self.user_id_label)
        
        user_info_layout.addStretch()
        
        layout.addWidget(user_info_frame)
        
        # ì¶œì„ ìƒíƒœ í”„ë ˆì„
        status_frame = QFrame()
        status_frame.setFixedHeight(ATTENDANCE_STATUS_HEIGHT)
        status_frame.setStyleSheet(f"""
            background-color: {ATTENDANCE_STATUS_BG_COLOR};
            border-radius: 8px;
            padding: 10px;
        """)
        
        status_layout = QVBoxLayout(status_frame)
        
        status_title = QLabel("ğŸ“Š ì¶œì„ ìƒíƒœ")
        status_title.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 14px; font-weight: bold;")
        status_layout.addWidget(status_title)
        
        self.attendance_status_label = QLabel("ëŒ€ê¸° ì¤‘...")
        self.attendance_status_label.setStyleSheet(f"color: {WARNING_COLOR}; font-size: 16px; font-weight: bold;")
        self.attendance_status_label.setAlignment(Qt.AlignCenter)
        status_layout.addWidget(self.attendance_status_label)
        
        self.detected_gesture_label = QLabel("ì œìŠ¤ì²˜: -")
        self.detected_gesture_label.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 12px;")
        status_layout.addWidget(self.detected_gesture_label)
        
        status_layout.addStretch()
        
        layout.addWidget(status_frame)
        
        layout.addStretch()
        
        return panel
    
    def create_gesture_guide(self):
        """í•˜ë‹¨ ì œìŠ¤ì²˜ ê°€ì´ë“œ ìƒì„±"""
        guide_frame = QFrame()
        guide_frame.setFixedHeight(GESTURE_GUIDE_HEIGHT)
        guide_frame.setStyleSheet(f"""
            background-color: {GESTURE_GUIDE_BG_COLOR};
            border-radius: 8px;
            padding: 10px;
        """)
        
        layout = QVBoxLayout(guide_frame)
        
        title = QLabel("ğŸ‘‹ ì œìŠ¤ì²˜ ê°€ì´ë“œ")
        title.setStyleSheet(f"color: {TEXT_COLOR}; font-size: 13px; font-weight: bold;")
        layout.addWidget(title)
        
        # ì œìŠ¤ì²˜ ëª©ë¡
        gestures_layout = QHBoxLayout()
        
        for gesture_name, gesture_info in GESTURES.items():
            gesture_widget = QLabel(f"{gesture_info['emoji']}\n{gesture_info['text']}")
            gesture_widget.setAlignment(Qt.AlignCenter)
            gesture_widget.setStyleSheet(f"""
                color: {gesture_info['color']};
                font-size: 11px;
                padding: 5px;
            """)
            gestures_layout.addWidget(gesture_widget)
        
        layout.addLayout(gestures_layout)
        
        return guide_frame
    
    def create_status_bar(self):
        """í•˜ë‹¨ ìƒíƒœë°” ìƒì„±"""
        status_bar = QLabel("âœ… ì¤€ë¹„ ì™„ë£Œ - ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”")
        status_bar.setFixedHeight(STATUS_BAR_HEIGHT)
        status_bar.setAlignment(Qt.AlignLeft | Qt.AlignVCenter)
        status_bar.setStyleSheet(f"""
            background-color: {STATUS_BAR_BG_COLOR};
            color: {TEXT_COLOR};
            font-size: {STATUS_FONT_SIZE}px;
            padding-left: 15px;
            border-radius: 5px;
        """)
        self.status_bar = status_bar
        return status_bar
    
    def get_button_style(self, font_size=LEFT_BUTTON_FONT_SIZE):
        """ë²„íŠ¼ ìŠ¤íƒ€ì¼ ë°˜í™˜"""
        return f"""
            QPushButton {{
                background-color: {BUTTON_COLOR};
                color: {TEXT_COLOR};
                border: none;
                border-radius: 5px;
                font-size: {font_size}px;
                font-weight: bold;
                padding: 5px;
            }}
            QPushButton:hover {{
                background-color: {BUTTON_HOVER_COLOR};
            }}
            QPushButton:pressed {{
                background-color: #1B1464;
            }}
        """
    
    def start_camera(self):
        """ì¹´ë©”ë¼ ì‹œì‘"""
        self.camera = cv2.VideoCapture(CAMERA_INDEX)
        
        if not self.camera.isOpened():
            self.update_status("âŒ ì¹´ë©”ë¼ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return
        
        # ì¹´ë©”ë¼ í•´ìƒë„ ì„¤ì •
        self.camera.set(cv2.CAP_PROP_FRAME_WIDTH, CAM_WIDTH)
        self.camera.set(cv2.CAP_PROP_FRAME_HEIGHT, CAM_HEIGHT)
        
        # íƒ€ì´ë¨¸ë¡œ í”„ë ˆì„ ì—…ë°ì´íŠ¸
        self.timer = QTimer()
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(int(1000 / CAMERA_FPS))
        
        self.update_status("ğŸ“¹ ì¹´ë©”ë¼ í™œì„±í™”ë¨")
    
    def load_face_data(self):
        """ì €ì¥ëœ ì–¼êµ´ ë°ì´í„° ë¡œë“œ"""
        face_data_file = "../data/face_data.pkl"
        
        if os.path.exists(face_data_file):
            try:
                with open(face_data_file, 'rb') as f:
                    data = pickle.load(f)
                    self.known_face_features = data.get('features', [])
                    self.known_face_names = data.get('names', [])
                print(f"âœ“ {len(self.known_face_names)}ëª…ì˜ ì–¼êµ´ ë°ì´í„° ë¡œë“œë¨")
            except Exception as e:
                print(f"âš ï¸  ì–¼êµ´ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        else:
            print("â„¹ï¸  ë“±ë¡ëœ ì–¼êµ´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def extract_face_features(self, detection, image_width, image_height):
        """ì–¼êµ´ ê°ì§€ ê²°ê³¼ì—ì„œ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ"""
        # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œë¥¼ íŠ¹ì§•ìœ¼ë¡œ ì‚¬ìš©
        bbox = detection.bounding_box
        features = [
            bbox.origin_x / image_width,
            bbox.origin_y / image_height,
            bbox.width / image_width,
            bbox.height / image_height
        ]
        return np.array(features)
    
    def cosine_similarity(self, vec1, vec2):
        """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0
        
        return dot_product / (norm1 * norm2)
    
    def recognize_faces(self, frame):
        """í”„ë ˆì„ì—ì„œ ì–¼êµ´ ì¸ì‹ (MediaPipe Task API ê¸°ë°˜)"""
        if not self.face_detector:
            # MediaPipeê°€ ì—†ìœ¼ë©´ OpenCV Haar Cascade ì‚¬ìš©
            return self.recognize_faces_opencv(frame)
        
        # MediaPipe Image ê°ì²´ ìƒì„±
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        mp_image = MPImage(image_format=mp.ImageFormat.SRGB, data=rgb_frame)
        
        # ì–¼êµ´ ê°ì§€
        detection_result = self.face_detector.detect(mp_image)
        
        recognized_names = []
        h, w, _ = frame.shape
        
        if detection_result.detections:
            for detection in detection_result.detections:
                # ë°”ìš´ë”© ë°•ìŠ¤ ì¶”ì¶œ
                bbox = detection.bounding_box
                x_min = int(bbox.origin_x)
                y_min = int(bbox.origin_y)
                x_max = int(bbox.origin_x + bbox.width)
                y_max = int(bbox.origin_y + bbox.height)
                
                # ì–¼êµ´ íŠ¹ì§• ì¶”ì¶œ
                current_features = self.extract_face_features(detection, w, h)
                
                # ë“±ë¡ëœ ì–¼êµ´ê³¼ ë¹„êµ
                best_match_name = "Unknown"
                best_similarity = 0
                
                for known_features, known_name in zip(self.known_face_features, self.known_face_names):
                    similarity = self.cosine_similarity(current_features, known_features)
                    
                    if similarity > best_similarity:
                        best_similarity = similarity
                        best_match_name = known_name
                
                # ìœ ì‚¬ë„ ì„ê³„ê°’ (0.98 ì´ìƒì´ë©´ ê°™ì€ ì‚¬ëŒ)
                confidence = best_similarity * 100
                if confidence < 98:
                    best_match_name = "Unknown"
                    confidence = 0
                
                if best_match_name != "Unknown":
                    recognized_names.append((best_match_name, confidence))
                
                # ì–¼êµ´ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                color = (0, 255, 0) if best_match_name != "Unknown" else (0, 0, 255)
                cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 2)
                
                # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ëˆˆ, ì½”, ì… ë“±)
                for keypoint in detection.keypoints:
                    kp_x = int(keypoint.x * w)
                    kp_y = int(keypoint.y * h)
                    cv2.circle(frame, (kp_x, kp_y), 2, (0, 255, 255), -1)
                
                # ì´ë¦„ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
                label_height = 40
                cv2.rectangle(frame, (x_min, y_max), (x_max, y_max + label_height), color, cv2.FILLED)
                
                if best_match_name != "Unknown":
                    cv2.putText(frame, best_match_name, (x_min + 6, y_max + 15), 
                               cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)
                    cv2.putText(frame, f"{confidence:.1f}%", (x_min + 6, y_max + 35), 
                               cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 255, 255), 1)
                else:
                    cv2.putText(frame, "Unknown", (x_min + 6, y_max + 25), 
                               cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)
        
        return frame, recognized_names
    
    def recognize_faces_opencv(self, frame):
        """í´ë°±: OpenCV Haar Cascadeë¡œ ì–¼êµ´ ê°ì§€"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Haar Cascade ë¶ˆëŸ¬ì˜¤ê¸°
        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        faces = face_cascade.detectMultiScale(gray, 1.1, 4)
        
        recognized_names = []
        
        for (x, y, w, h) in faces:
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(frame, "Face Detected", (x, y-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        return frame, recognized_names
    
    def update_frame(self):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ì—…ë°ì´íŠ¸"""
        ret, frame = self.camera.read()
        
        if ret:
            self.current_frame = frame
            display_frame = frame.copy()
            
            # ì–¼êµ´ ì¸ì‹ ëª¨ë“œì¼ ë•Œ ì²˜ë¦¬
            if self.current_mode == "face_attendance":
                display_frame, recognized_names = self.recognize_faces(display_frame)
                
                # ì¸ì‹ëœ ì‚¬ëŒ ì •ë³´ ì—…ë°ì´íŠ¸
                if recognized_names:
                    name, confidence = recognized_names[0]  # ì²« ë²ˆì§¸ ì¸ì‹ëœ ì‚¬ëŒ
                    self.user_name_label.setText(f"ì´ë¦„: {name}")
                    self.attendance_status_label.setText(f"ì¸ì‹ë¨ ({confidence:.1f}%)")
                    self.attendance_status_label.setStyleSheet(
                        f"color: {SUCCESS_COLOR}; font-size: 16px; font-weight: bold;"
                    )
                    
                    # ìë™ ì¶œì„ ì²˜ë¦¬ (confidence > 80%)
                    if confidence > 80:
                        self.detected_gesture_label.setText(f"âœ“ {name} ì¶œì„ í™•ì¸")
                else:
                    self.detected_gesture_label.setText("ì–¼êµ´: ê°ì§€ ì•ˆë¨")
            
            # ëª¨ë“œ í‘œì‹œ
            if self.current_mode:
                mode_text = {
                    "gesture_attendance": "ì œìŠ¤ì²˜ ì¶œì„ ëª¨ë“œ",
                    "face_attendance": "ì–¼êµ´ ì¸ì‹ ëª¨ë“œ",
                }
                cv2.putText(display_frame, mode_text.get(self.current_mode, ""), 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # BGRì„ RGBë¡œ ë³€í™˜
            rgb_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            
            # QImageë¡œ ë³€í™˜
            h, w, ch = rgb_frame.shape
            bytes_per_line = ch * w
            qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
            
            # QLabelì— í‘œì‹œ
            pixmap = QPixmap.fromImage(qt_image)
            scaled_pixmap = pixmap.scaled(CAM_WIDTH, CAM_HEIGHT, Qt.KeepAspectRatio)
            self.camera_label.setPixmap(scaled_pixmap)
    
    def on_mode_button_click(self, mode_name):
        """ëª¨ë“œ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸"""
        self.current_mode = mode_name
        
        if mode_name == "gesture_attendance":
            self.update_status("âœ‹ ì œìŠ¤ì²˜ ì¶œì„ ëª¨ë“œ í™œì„±í™”")
            self.attendance_status_label.setText("ì œìŠ¤ì²˜ ëŒ€ê¸° ì¤‘...")
            self.attendance_status_label.setStyleSheet(f"color: {WARNING_COLOR}; font-size: 16px; font-weight: bold;")
            
        elif mode_name == "face_attendance":
            self.update_status("ğŸ˜Š ì–¼êµ´ ì¸ì‹ ì¶œì„ ëª¨ë“œ í™œì„±í™”")
            self.attendance_status_label.setText("ì–¼êµ´ ì¸ì‹ ì¤‘...")
            self.attendance_status_label.setStyleSheet(f"color: {ACCENT_COLOR}; font-size: 16px; font-weight: bold;")
            
        elif mode_name == "attendance_status":
            self.update_status("ğŸ“Š ì¶œì„ í˜„í™© ì¡°íšŒ")
            QMessageBox.information(self, "ì¶œì„ í˜„í™©", "ì¶œì„ í˜„í™© ì¡°íšŒ ê¸°ëŠ¥ì…ë‹ˆë‹¤.")
    
    def update_status(self, message):
        """ìƒíƒœë°” ì—…ë°ì´íŠ¸"""
        self.status_bar.setText(message)
    
    def closeEvent(self, event):
        """ìœˆë„ìš° ì¢…ë£Œ ì´ë²¤íŠ¸"""
        if self.camera is not None:
            self.camera.release()
        if MEDIAPIPE_AVAILABLE:
            if hasattr(self, 'face_detector') and self.face_detector:
                self.face_detector.close()
            if hasattr(self, 'gesture_recognizer') and self.gesture_recognizer:
                self.gesture_recognizer.close()
        event.accept()


def main():
    app = QApplication(sys.argv)
    
    # ë‹¤í¬ í…Œë§ˆ ì ìš©
    app.setStyle('Fusion')
    palette = QPalette()
    palette.setColor(QPalette.Window, QColor(30, 39, 46))
    palette.setColor(QPalette.WindowText, Qt.white)
    app.setPalette(palette)
    
    window = ClientUI()
    window.show()
    
    sys.exit(app.exec_())


if __name__ == "__main__":
    main()
